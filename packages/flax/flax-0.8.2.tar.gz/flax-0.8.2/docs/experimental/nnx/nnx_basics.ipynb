{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNX Basics\n",
    "\n",
    "NNX is a **N**eural **N**etworks JA**X** library that embraces Python's object-oriented programming \n",
    "model to provide an intuitive and highly simplified user experience. It aims to empower users\n",
    "by making Modules very easy to integrate with any JAX API, it achieves this through a very small set\n",
    "of primitives known as the [Functional API](#the-functional-api). NNX is specifically designed to support \n",
    "all the patterns that allowed Linen to scale to large code bases building upon a much simpler foundation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.experimental import nnx\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Module System\n",
    "To begin lets see how to create a `Linear` Module using NNX. The main noticeable\n",
    "different between Module systems like Haiku or Linen and NNX is that in NNX everything is\n",
    "**explicit**. This means amongst other things that 1) the Module itself holds the state \n",
    "(e.g. parameters) directly, 2) the RNG state is threaded by the user, and 3) all shape information\n",
    "must be provided on initialization (no shape inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nnx.Module):\n",
    "  def __init__(self, din: int, dout: int, *, rngs: nnx.Rngs):\n",
    "    key = rngs.params()\n",
    "    self.w = nnx.Param(jax.random.uniform(key, (din, dout)))\n",
    "    self.b = nnx.Param(jnp.zeros((dout,)))\n",
    "    self.din, self.dout = din, dout\n",
    "\n",
    "  def __call__(self, x: jax.Array):\n",
    "    return x @ self.w.value + self.b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above dynamic state is stored in `nnx.Variable`s such as `nnx.Param`,\n",
    "and static state (all types not handled by NNX) such as integers or strings \n",
    "are stored directly. RNG keys can be requested from the `nnx.Rngs` object\n",
    "by calling `rngs.<stream_name>()` where the stream name show match on of the names provided to the `Rngs` constructor (shown below).\n",
    "\n",
    "To actually initialize a Module is very easy: simply call the constructor. All of the\n",
    "parameters of a Module will be created right then and there, and are immediately available\n",
    "for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = Linear(\n",
      "  din=2,\n",
      "  dout=3\n",
      ")\n",
      "model.w.value = Array([[0.19007349, 0.31424356, 0.3686391 ],\n",
      "       [0.7862853 , 0.03352201, 0.50682676]], dtype=float32)\n",
      "model.b.value = Array([0., 0., 0.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = Linear(din=2, dout=3, rngs=nnx.Rngs(params=0))\n",
    "\n",
    "print(f'{model = }')\n",
    "print(f'{model.w.value = }')\n",
    "print(f'{model.b.value = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very handy for debugging as it allows accessing the entire structure or\n",
    "modify it. Similarly, computation can be ran directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0.9763588 , 0.34776556, 0.87546587]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.ones((1, 2))\n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Modules hold their own state there is no need for a separate `apply` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stateful Computation\n",
    "\n",
    "When implementing layers like Batch Normalization or Multi Head Attention with \n",
    "autoregressive decoding you often need to store and update state inside a Module \n",
    "during the forward pass. The way to do this in NNX is simply to store the state \n",
    "inside a `Variable` and update it in-place when need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counter.count.value = 0\n",
      "counter.count.value = 1\n"
     ]
    }
   ],
   "source": [
    "class Counter(nnx.Module):\n",
    "  def __init__(self):\n",
    "    self.count = nnx.Variable(0)\n",
    "\n",
    "  def __call__(self):\n",
    "    self.count.value += 1\n",
    "\n",
    "counter = Counter()\n",
    "print(f'{counter.count.value = }')\n",
    "counter()\n",
    "print(f'{counter.count.value = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This looks too easy, what is the catch?** \n",
    "JAX frameworks have avoided mutable references until now. The key innovations which \n",
    "allows their usage in NNX is that 1) there is a clear boundary between reference \n",
    "semantics and value semantics, defined by [The Functional API](#the-functional-api),\n",
    "and 2) there are guards in place to avoid updating NNX objects from a `MainTrace`, \n",
    "thus preventing tracer leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Modules\n",
    "\n",
    "As expected, Modules can used to compose other Modules in a nested\n",
    "structure, this includes standard Modules such as `nnx.Linear`,\n",
    "`nnx.Conv`, etc, or any custom Module created by users. Modules can \n",
    "be assigned as attributes of a Module, but shown by `MLP.blocks` in the\n",
    "example below, they can also be stored in attributes of type `list`, `dict`, `tuple`, \n",
    "or nested structues of the previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = MLP(\n",
      "  blocks=[Block(\n",
      "      linear=Linear(\n",
      "            in_features=2,\n",
      "            out_features=2,\n",
      "            use_bias=True,\n",
      "            dtype=None,\n",
      "            param_dtype=<class 'jax.numpy.float32'>,\n",
      "            precision=None,\n",
      "            kernel_init=<function variance_scaling.<locals>.init at 0x169773f70>,\n",
      "            bias_init=<function zeros at 0x1353b8ca0>,\n",
      "            dot_general=<function dot_general at 0x126dc5700>\n",
      "          ),\n",
      "      bn=BatchNorm(\n",
      "            num_features=2,\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "class Block(nnx.Module):\n",
    "  def __init__(self, dim: int, *, rngs: nnx.Rngs):\n",
    "    self.linear = nnx.Linear(dim, dim, rngs=rngs)\n",
    "    self.bn = nnx.BatchNorm(dim, use_running_average=True, rngs=rngs)\n",
    "\n",
    "  def __call__(self, x: jax.Array):\n",
    "    return nnx.relu(self.bn(self.linear(x)))\n",
    "  \n",
    "class MLP(nnx.Module):\n",
    "  def __init__(self, num_layers: int, dim: int, *, rngs: nnx.Rngs):\n",
    "    self.blocks = [Block(dim, rngs=rngs) for _ in range(num_layers)]\n",
    "  \n",
    "  def __call__(self, x: jax.Array):\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "    return x\n",
    "  \n",
    "model = MLP(num_layers=5, dim=2, rngs=nnx.Rngs(0))\n",
    "print(f'{model = }'[:500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the benefits of NNX is that nested Modules as easy to inspect and\n",
    "static analyzers can help you while doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.blocks[1].linear.kernel.value = Array([[0.992858 , 0.9711272],\n",
      "       [1.4061186, 0.4704619]], dtype=float32)\n",
      "model.blocks[0].bn.scale.value = Array([1., 1.], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(f'{model.blocks[1].linear.kernel.value = }')\n",
    "print(f'{model.blocks[0].bn.scale.value = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Surgery\n",
    "NNX Modules are mutable by default, this means their structure can be changed\n",
    "at any time. Also, NNX's Module system supports reference sharing of Modules and\n",
    "Variables.\n",
    "\n",
    "The previous makes Model Surgery quite easy as any submodule could be replace by\n",
    "e.g. a pretrained Module, a shared Module, or even just a Module/function that\n",
    "uses the same signature. More over, Variables can also be modified or shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Module replacement\n",
    "pretrained = Block(dim=2, rngs=nnx.Rngs(42)) # imagine this is pretrained\n",
    "model.blocks[0] = pretrained\n",
    "# Module sharing\n",
    "model.blocks[3] = model.blocks[1]\n",
    "# Monkey patching\n",
    "def awesome_layer(x): return x\n",
    "model.blocks[2] = awesome_layer\n",
    "\n",
    "# Variable sharing (weight tying)\n",
    "model.blocks[-1].linear.kernel = model.blocks[0].linear.kernel\n",
    "\n",
    "model(jnp.ones((1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Functional API\n",
    "\n",
    "The Functional API established a clear boundary between reference/object semantics and \n",
    "value/pytree semantics. It also allows same amount of fine-grained control over the \n",
    "state Linen/Haiku users are used to. The Functional API consists of 3 basic methods: \n",
    "`split`, `merge`, and `update`.\n",
    "\n",
    "The `StatefulLinear` Module shown below will serve as an example to learn to use the \n",
    "Functional API. It contains some `nnx.Param` Variables and a custom `Count` Variable\n",
    "type which is used to keep track of integer scalar state that increases on every \n",
    "forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Count(nnx.Variable): pass\n",
    "\n",
    "class StatefulLinear(nnx.Module):\n",
    "  def __init__(self, din: int, dout: int, *, rngs: nnx.Rngs):\n",
    "    self.w = nnx.Param(jax.random.uniform(rngs(), (din, dout)))\n",
    "    self.b = nnx.Param(jnp.zeros((dout,)))\n",
    "    self.count = Count(0)\n",
    "\n",
    "  def __call__(self, x: jax.Array):\n",
    "    self.count.value += 1\n",
    "    return x @ self.w.value + self.b.value\n",
    "  \n",
    "model = StatefulLinear(din=2, dout=3, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and GraphDef\n",
    "\n",
    "A Module can be decomposed into a `State` and `GraphDef` pytrees using the \n",
    "`.split()` method. State is a Mapping from strings to Variables or nested \n",
    "States. GraphDef is contains all the static information needed to reconstruct \n",
    "a Module graph, its analogous to JAX's `PyTreeDef`, and for convenience it \n",
    "implements an empty pytree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state = State({\n",
      "  'w': Param(\n",
      "    raw_value=Array([[0.19007349, 0.31424356, 0.3686391 ],\n",
      "           [0.7862853 , 0.03352201, 0.50682676]], dtype=float32)\n",
      "  ),\n",
      "  'b': Param(\n",
      "    raw_value=Array([0., 0., 0.], dtype=float32)\n",
      "  ),\n",
      "  'count': Count(\n",
      "    raw_value=0\n",
      "  )\n",
      "})\n",
      "\n",
      "static = GraphDef(\n",
      "  type=StatefulLinear,\n",
      "  index=0,\n",
      "  attributes=('w', 'b', 'count'),\n",
      "  subgraphs={},\n",
      "  static_fields={},\n",
      "  variables={\n",
      "    'w': VariableDef(\n",
      "      type=Param,\n",
      "      index=1,\n",
      "      me...\n"
     ]
    }
   ],
   "source": [
    "state, static = model.split()\n",
    "\n",
    "print(f'{state = }\\n')\n",
    "print(f'{static = }'[:200] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, Merge, and Update\n",
    "\n",
    "`merge` is the reverse of `split`, it takes the GraphDef + State and reconstructs\n",
    "the Module. As shown in the example below, by using split and merge in sequence \n",
    "any Module can be lifted to be used in any JAX transform. `update` can\n",
    "update a Module strucure from a compatible State, this is often used to propagate the state\n",
    "updates from a transform back to the source object outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.count = Count(\n",
      "  raw_value=0\n",
      ")\n",
      "model.count.value = Array(1, dtype=int32, weak_type=True)\n"
     ]
    }
   ],
   "source": [
    "print(f'{model.count = }')\n",
    "\n",
    "# 1. Use split to create a pytree representation of the Module\n",
    "state, static = model.split()\n",
    "\n",
    "@jax.jit\n",
    "def forward(static: nnx.GraphDef, state: nnx.State, x: jax.Array):\n",
    "  # 2. Use merge to create a new model inside the JAX transformation\n",
    "  model = static.merge(state)\n",
    "  # 3. Call the Module\n",
    "  y = model(x)\n",
    "  # 4. Use split to propagate State updates\n",
    "  state, _ = model.split()\n",
    "  return y, state\n",
    "\n",
    "y, state = forward(static, state, x=jnp.ones((1, 2)))\n",
    "# 5. Update the state of the original Module\n",
    "model.update(state)\n",
    "\n",
    "print(f'{model.count.value = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key insight of this pattern is that using mutable references is \n",
    "fine within a transform context (including the base eager interpreter)\n",
    "but its necessary to use the Functional API when crossing boundaries.\n",
    "\n",
    "**Why aren't Module's just Pytrees?** The main reason is that its very\n",
    "easy to lose track of shared references by accident this way, for example\n",
    "if you pass two Module that have a shared Module through a JAX boundary\n",
    "you will silently lose that shared reference. The Functional API makes this\n",
    "behavior explicit and thus its much easier to reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained State Control\n",
    "\n",
    "Seasoned Linen and Haiku users might recognize that having all the state in\n",
    "a single structure is not always the best choice as there are cases in which\n",
    "you might want to handle different subsets of the state differently. This a\n",
    "common occurrence when interacting with JAX transform, for example, not all\n",
    "the model's state can or should be differentiated when interacting which `grad`,\n",
    "or sometimes there is a need to specify what part of the model's state is a\n",
    "carry and what part is not when using `scan`.\n",
    "\n",
    "To solve this `split` allows you to pass one or more `Filter`s to partition\n",
    "the Variables into mutually exclusive States. The most common Filter being\n",
    "Variable types as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = State({\n",
      "  'w': Param(\n",
      "    raw_value=Array([[0.19007349, 0.31424356, 0.3686391 ],\n",
      "           [0.7862853 , 0.03352201, 0.50682676]], dtype=float32)\n",
      "  ),\n",
      "  'b': Param(\n",
      "    raw_value=Array([0., 0., 0.], dtype=float32)\n",
      "  )\n",
      "})\n",
      "\n",
      "counts = State({\n",
      "  'count': Count(\n",
      "    raw_value=Array(1, dtype=int32, weak_type=True)\n",
      "  )\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# use Variable type filters to split into multiple States\n",
    "params, counts, static = model.split(nnx.Param, Count)\n",
    "\n",
    "print(f'{params = }\\n')\n",
    "print(f'{counts = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: filters must be exhaustive, if a Variable is not matched an error will be raised.\n",
    "\n",
    "As expected the `merge` and `update` methods naturally consume multiple States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge multiple States\n",
    "model = static.merge(params, counts)\n",
    "# update with multiple States\n",
    "model.update(params, counts)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
