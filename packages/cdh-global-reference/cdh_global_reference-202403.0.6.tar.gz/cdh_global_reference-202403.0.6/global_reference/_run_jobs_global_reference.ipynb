{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Job Action List\n",
    "\n",
    "## Checklist to Complete Prior to Run\n",
    "\n",
    "Ensure the follow steps are complete before running the notebook.\n",
    "\n",
    "1. Run this notebook from the CDH_Cluster_Python_SQL_UC_Shared cluster in dev to perform process_ingress or process_data actions.\n",
    "    Users will need to be in the AD - developer or administrator groups to have permission to perform these actions.\n",
    "    Users in the analyst group will likely not have ADLS write file permission, particularly to the database container.\n",
    "2. Ensure the service principal EDAV_DATAHUB_DEV: e08bf725-02ed-4bb6-83dd-2211235be8b1 has full rights to repo in dev\n",
    "    or the run_analytics_processing action will fail saving to repo.\n",
    "3. Ensure the service principal secret is available in databricks secret apps-client-secret scope dbs-scope-CDH.\n",
    "4. Ensure the az_sub_client_id in config json is set to service principal for project : EDAV_DATAHUB_DEV :\n",
    "    140ec12a-3b3d-4138-8294-57d6c0e82dd6.\n",
    "5. Ensure the cdh_oauth_databricks_resource_id is config json is set to service principal for databricks :\n",
    "    AzureDatabricks : 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d.\n",
    "6. Run show users in the cdh_global_reference database and make sure that EDAV_DATAHUB_DEV is a user in Databricks SQL.\n",
    "7. Ensure all developers and EDAV_DATAHUB_DEV are members of AD Group gp-u-EDAV-CDH-DEV-DBR-ADMIN.\n",
    "8. Ensure AD Group gp-u-EDAV-CDH-DEV-DBR-ADMIN is the owner of the database cdh_global_reference.\n",
    "9. Double check / set default values in the first cell of the template notebook such as default_environment\n",
    "    - default_environment = \"dev\" (if not set will use ENVIRONMENT variable)\n",
    "    - default_data_product_id = \"global_reference\" (should default based on directory)\n",
    "10. Upload input and configurations file to appropriate containers and folders (create containers if necessary)\n",
    "    - ingress directory requires subdirectories named per source abbreviation with the files listed in dataset list for\n",
    "        the following sources\n",
    "    - ingress directory requires subdirectory to hold json config output\n",
    "        - config\n",
    "    - config directory requires\n",
    "        - cdh folder with csv configurations (currently populated from Excel with manual upload)\n",
    "        - json config file root for each ENVIRONMENT\n",
    "    - autogenerated folder needs to exist below /cdh/reference_data/autogenerated with subfolders\n",
    "        - python\n",
    "        - sql\n",
    "11. Ensure that you are running from a cluster that support ad pass through or you have configured spark oauth\n",
    "        clientid and client secret.\n",
    "12. To debug library source code from notebook \n",
    "    - cd cdh_dav_python\n",
    "    - pip install -e .\n",
    "\n",
    "## Usage Instructions\n",
    "\n",
    "* Select JOB_NAME from drop down. This filters an array list of job actions to perform.\n",
    "* List can contain one or more job action items associated with the job name.\n",
    "* Job actions are configure in the job tab in the data life cycle Excel.\n",
    "\n",
    "### Run Job - Interactively\n",
    "\n",
    "* Select the name of the job to run\n",
    "* Select the as of Year (YYYY), Month (MM) and Day (DD or NA for blank)\n",
    "* Run notebook\n",
    "\n",
    "This script is used to run job actions in the CDH (CDC Data Hub) project.\n",
    "It provides a checklist of steps to complete before running the notebook and usage instructions for running\n",
    "the job interactively.\n",
    "\n",
    "The script imports necessary modules and defines functions for installing Python packages,\n",
    "setting up the environment, and running job actions.\n",
    "It also includes code for handling different execution environments, such as Databricks and local.\n",
    "\n",
    "To run a job, select the job name from a dropdown list and provide additional parameters such as the\n",
    "as of year, month, and day.\n",
    "The script then executes the specified job using the provided parameters.\n",
    "\n",
    "Supported methods for running actions in the global-reference/cdh_lava_lib:\n",
    "1. Run job interactively via this notebook in databricks\n",
    "2. Run job from another Databricks notebook (Python, Scala, R) by calling dbutils.run\n",
    "3. Run job from bash, powershell, or DevOps notebook by calling a Python shell script\n",
    "4. Run job from a Python Jupyter notebook by calling the library API directly\n",
    "5. Run job from a functional call inside a Databricks Python notebook by calling the function\n",
    "6. Run job from VS Code in a client server set up using a Databricks session\n",
    "7. Run job from VS Code using a local spark server without using Databricks\n",
    "\n",
    "Note: Before running the script, ensure that the necessary requirements are installed and\n",
    "the environment is properly configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001frun_install_cdh_lava_core\u001f654\u001fINFO\u001ftracer: <opentelemetry.sdk.trace.Tracer object at 0x7f64fa843010>\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:tracer: <opentelemetry.sdk.trace.Tracer object at 0x7f64fa843010>\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_core\u001f69\u001fINFO\u001fvirtual_env: reference_data_dev\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:virtual_env: reference_data_dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/developer/projects/cdh-ref/reference_data\n",
      "Parent Directory: /home/developer/projects/cdh-ref\n",
      "/home/developer/projects/cdh-ref/cdh_lava_core_lib\n",
      "/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core\n",
      "Files in Parent Directory: ['cdh_lava_core_lib', '.vscode', 'poetry.lock', 'yarn.lock', 'README.md', 'docs', '.python-version', 'setup.py', 'cdh_ref', '.git', '.pytest_cache', '.gitignore', '.gitmodules', 'package.json', 'poetry.toml', '.VSCodeCounter', 'setup.cfg', 'pyproject.toml', 'configs', 'requirements.txt', 'reference_data', '.github', '.databricks']\n",
      "running_local: False\n",
      "initial_script_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "parent_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "initial_script_directory: /home/developer/projects/cdh-ref/reference_data\n",
      "library_root: /home/developer/projects/cdh-ref/cdh_lava_core_lib\n",
      "script_directory:/home/developer/projects/cdh-ref/reference_data\n",
      "Package cdh_ref is already installed.\n",
      "absolute_path: /home/developer/projects/cdh-ref/reference_data/config/bronze_sps_config_jobs.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1010df00924227b188fb36264e3b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='report_yyyy'), Dropdown(index=3, options=('2021', '2022', '2023', '2024'), value='2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2598ac6f36402080de9cedc56864f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='report_mm'), Dropdown(index=2, options=('01', '02', '03', '04', '05', '06', '07', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db062a5f03eb447aad2662fb6e4ac544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Label(value='report_dd'), Dropdown(options=('NA', '01', '02', '03', '04', '05', '06', '07', '08'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f164\u001fINFO\u001fconfig_jobs_path:/home/developer/projects/cdh-ref/reference_data/config/bronze_sps_config_jobs.csv\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:config_jobs_path:/home/developer/projects/cdh-ref/reference_data/config/bronze_sps_config_jobs.csv\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f190\u001fINFO\u001fjob_name_values_list:['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs']\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:job_name_values_list:['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs']\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f191\u001fINFO\u001fconfig_jobs_path:/home/developer/projects/cdh-ref/reference_data/config/bronze_sps_config_jobs.csv\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:config_jobs_path:/home/developer/projects/cdh-ref/reference_data/config/bronze_sps_config_jobs.csv\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f195\u001fINFO\u001fjob_name widget:process_data_where_source_abbreviation_name_is_phvs\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:job_name widget:process_data_where_source_abbreviation_name_is_phvs\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1112\u001fINFO\u001finitial parameters: {'environment': 'dev', 'data_product_id_root': 'reference', 'data_product_id_individual': 'data', 'data_product_id': 'reference_data', 'yyyy': '2024', 'mm': '03', 'dd': 'NA', 'repository_path': '/home/developer/projects/cdh-ref/reference_data', 'dataset_name': 'all', 'cicd_action': 'pull_request', 'running_local': False, 'array_jobs': ['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs'], 'data_product_root_id': 'reference', 'data_product_individual_id': 'data'}\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:initial parameters: {'environment': 'dev', 'data_product_id_root': 'reference', 'data_product_id_individual': 'data', 'data_product_id': 'reference_data', 'yyyy': '2024', 'mm': '03', 'dd': 'NA', 'repository_path': '/home/developer/projects/cdh-ref/reference_data', 'dataset_name': 'all', 'cicd_action': 'pull_request', 'running_local': False, 'array_jobs': ['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs'], 'data_product_root_id': 'reference', 'data_product_individual_id': 'data'}\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f685\u001fINFO\u001frepository_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:repository_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1128\u001fINFO\u001fReceived the following parameters: parameters={'environment': 'dev', 'data_product_id_root': 'reference', 'data_product_id_individual': 'data', 'data_product_id': 'reference_data', 'yyyy': '2024', 'mm': '03', 'dd': 'NA', 'repository_path': '/home/developer/projects/cdh-ref/reference_data', 'dataset_name': 'all', 'cicd_action': 'pull_request', 'running_local': False, 'array_jobs': ['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs'], 'data_product_root_id': 'reference', 'data_product_individual_id': 'data'}, running_local=False, data_product_id=reference_data, environment=dev, data_product_id_root=reference, yyyy_param=2024, mm_param=03, dd_param=NA, dataset_name=all, cicd_action=pull_request, repository_path=/home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Received the following parameters: parameters={'environment': 'dev', 'data_product_id_root': 'reference', 'data_product_id_individual': 'data', 'data_product_id': 'reference_data', 'yyyy': '2024', 'mm': '03', 'dd': 'NA', 'repository_path': '/home/developer/projects/cdh-ref/reference_data', 'dataset_name': 'all', 'cicd_action': 'pull_request', 'running_local': False, 'array_jobs': ['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs'], 'data_product_root_id': 'reference', 'data_product_individual_id': 'data'}, running_local=False, data_product_id=reference_data, environment=dev, data_product_id_root=reference, yyyy_param=2024, mm_param=03, dd_param=NA, dataset_name=all, cicd_action=pull_request, repository_path=/home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1146\u001fINFO\u001finitial repository_path:/home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:initial repository_path:/home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/reference/data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f753\u001fINFO\u001fThe env_folder_path directory /home/developer/projects/cdh-ref/reference_data/reference/data/ does not exist.\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:The env_folder_path directory /home/developer/projects/cdh-ref/reference_data/reference/data/ does not exist.\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/reference/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f776\u001fINFO\u001fcdh_folder_config_path:/home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:cdh_folder_config_path:/home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/config/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f795\u001fINFO\u001fcheck 1 attempt: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:check 1 attempt: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f932\u001fINFO\u001frepository_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:repository_path: /home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f933\u001fINFO\u001fenvironment_json_path: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:environment_json_path: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1158\u001fINFO\u001fupdated repository_path:/home/developer/projects/cdh-ref/reference_data/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:updated repository_path:/home/developer/projects/cdh-ref/reference_data/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f166\u001fINFO\u001fconvert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_current_os_dir: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f239\u001fINFO\u001fconvert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:convert_to_unix_dir: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_file\u001f176\u001fINFO\u001fconverted_path: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:converted_path: /home/developer/projects/cdh-ref/reference_data/reference/reference_data/cicd/\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1071\u001fINFO\u001fSuccessfuully processed configuration.\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Successfuully processed configuration.\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1180\u001fINFO\u001fConfiguration found environment_json_path: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Configuration found environment_json_path: /home/developer/projects/cdh-ref/reference_data/config/config.dev.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: {'environment': 'dev', 'data_product_id_root': 'reference', 'data_product_id_individual': 'data', 'data_product_id': 'reference_data', 'yyyy': '2024', 'mm': '03', 'dd': 'NA', 'repository_path': '/home/developer/projects/cdh-ref/reference_data', 'dataset_name': 'all', 'cicd_action': 'pull_request', 'running_local': False, 'array_jobs': ['Select job to run', 'process_analytics', 'process_data', 'process_data_where_source_abbreviation_name_is_phvs', 'process_ingress', 'process_ingress_where_source_abbreviation_name_is_athena', 'process_ingress_where_source_abbreviation_name_is_phvs'], 'data_product_root_id': 'reference', 'data_product_individual_id': 'data'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:reference_data:running_local: False\n",
      "INFO:reference_data:env_file_path: /home/developer/share/.env\n",
      "INFO:reference_data:default_connection_string: InstrumentationKey=8f02ef9a-cd94-48cf-895a-367f102e8a24;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\n",
      "INFO:reference_data:application_insights_connection_string: InstrumentationKey=8f02ef9a-cd94-48cf-895a-367f102e8a24;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\n",
      "INFO:reference_data:dotenv_file: /home/developer/share/.env\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1265\u001fINFO\u001fRetrieving Databricks secret for apps-client-secret.\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Retrieving Databricks secret for apps-client-secret.\n",
      "2024-03-06 21:58:57\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_metadata\u001f1266\u001fINFO\u001fRetrieving Databricks secret for apps-client-secret.\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Retrieving Databricks secret for apps-client-secret.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_connection_string: InstrumentationKey=8f02ef9a-cd94-48cf-895a-367f102e8a24;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\n",
      "application_insights_connection_string: InstrumentationKey=8f02ef9a-cd94-48cf-895a-367f102e8a24;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\n",
      "dotenv_file: /home/developer/share/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 21:58:58\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fsecurity_core\u001f162\u001fERROR\u001fFile : /home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/msal/authority.py , Line : 165, Func.Name : canonicalize, Message : raise ValueError(, Type : <class 'ValueError'>, Value : Your given address (https://login.microsoftonline.com9ce70869-60db-44fd-abe8-d2767077fc8f) should consist of an https url with a minimum of one segment in a path: e.g. https://login.microsoftonline.com/{tenant} or https://{tenant_name}.ciamlogin.com/{tenant} or https://{tenant_name}.b2clogin.com/{tenant_name}.onmicrosoft.com/policy\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:File : /home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/msal/authority.py , Line : 165, Func.Name : canonicalize, Message : raise ValueError(, Type : <class 'ValueError'>, Value : Your given address (https://login.microsoftonline.com9ce70869-60db-44fd-abe8-d2767077fc8f) should consist of an https url with a minimum of one segment in a path: e.g. https://login.microsoftonline.com/{tenant} or https://{tenant_name}.ciamlogin.com/{tenant} or https://{tenant_name}.b2clogin.com/{tenant_name}.onmicrosoft.com/policy\n",
      "2024-03-06 21:58:58\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fsecurity_core\u001f165\u001fINFO\u001ftoken_response: [REDACTED]: length:26\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:token_response: [REDACTED]: length:26\n",
      "2024-03-06 21:58:58\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f859\u001fINFO\u001fjob_name: process_data_where_source_abbreviation_name_is_phvs started\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:job_name: process_data_where_source_abbreviation_name_is_phvs started\n",
      "2024-03-06 21:58:58\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f516\u001fINFO\u001frunning_local:False\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:running_local:False\n",
      "2024-03-06 21:58:58\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fdatabase\u001f64\u001fINFO\u001fshow databases in edav_dev_cdh like 'cdh_reference'\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:show databases in edav_dev_cdh like 'cdh_reference'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquire_access_token_with_client_credentials for reference_data\n",
      "az_sub_oauth_token_endpoint:https://login.microsoftonline.com/9ce70869-60db-44fd-abe8-d2767077fc8f\n",
      "sp_client_id:e08bf725-02ed-4bb6-83dd-2211235be8b1\n",
      "azure_databricks_resource_id:2ff814a6-3304-4ab8-85cb-cd0e6f879c1d\n",
      "catalog_name: edav_dev_cdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 21:59:14\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fdatabase\u001f76\u001fINFO\u001fDatabase cdh_reference already exists.\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:Database cdh_reference already exists.\n",
      "2024-03-06 21:59:38\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f533\u001fINFO\u001fdf_datasets unfiltered count:10\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:df_datasets unfiltered count:10\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type type for attribute 'parameter_cls' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type type for attribute 'parameter_cls' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type SparkSession for attribute 'parameter_spark' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'parameter_account_name' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type type for attribute 'parameter_cls' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type dict for attribute 'parameter_config' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type SparkSession for attribute 'parameter_spark' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type EnvironmentMetaData for attribute 'parameter_obj_env_metadata' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type dict for attribute 'parameter_config' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type SparkSession for attribute 'parameter_spark' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type type for attribute 'parameter_cls' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type EnvironmentMetaData for attribute 'parameter_obj_env' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type SparkSession for attribute 'parameter_spark' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type dict for attribute 'parameter_config' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fjob_metadata\u001f913\u001fINFO\u001fjob_name: process_data_where_source_abbreviation_name_is_phvs failed\n",
      "INFO:cdh_lava_core_lib:run_install_cdh_lava_core.py:job_name: process_data_where_source_abbreviation_name_is_phvs failed\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f430\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "\n",
      "2024-03-06 21:59:39\u001fcdh_lava_core_lib:run_install_cdh_lava_core.py\u001fenvironment_logging\u001f438\u001fERROR\u001f('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n",
      "WARNING:opentelemetry.attributes:Invalid type type for attribute 'parameter_cls' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type EnvironmentMetaData for attribute 'parameter_obj_env' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type SparkSession for attribute 'parameter_spark' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type dict for attribute 'parameter_config' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type RemoteDbUtils for attribute 'parameter_dbutils' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "ERROR:cdh_lava_core_lib:run_install_cdh_lava_core.py:('Error: %s', ResourceDoesNotExist('No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.')): ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.:   File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 896, in run_job_name\n",
      "    result = cls.run_job_action(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1042, in run_job_action\n",
      "    raise ex\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 1002, in run_job_action\n",
      "    results = cls.run_data_processing(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py\", line 534, in run_data_processing\n",
      "    df_columns = obj_env_metadata.get_column_list(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 290, in get_column_list\n",
      "    file_size = cls.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py\", line 381, in get_file_size\n",
      "    file_size = obj_env_file.get_file_size(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 729, in get_file_size\n",
      "    file_exists = cls.file_exists(\n",
      "  File \"/home/developer/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py\", line 995, in file_exists\n",
      "    dbutils.fs.ls(path)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py\", line 55, in ls\n",
      "    for f in self._dbfs.list(dir):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py\", line 342, in list\n",
      "    for file_info in super().list(path):\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py\", line 510, in list\n",
      "    json = self._api.do('GET', '/api/2.0/dbfs/list', query=query, headers=headers)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 130, in do\n",
      "    response = retryable(self._perform)(method,\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 54, in wrapper\n",
      "    raise err\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py\", line 33, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/developer/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py\", line 238, in _perform\n",
      "    raise self._make_nicer_error(response=response, **payload) from None\n",
      "databricks.sdk.errors.platform.ResourceDoesNotExist: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.\n"
     ]
    },
    {
     "ename": "ResourceDoesNotExist",
     "evalue": "No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceDoesNotExist\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 112\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEFAULT_JOB_NAME \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect job to run\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    111\u001b[0m     config_jobs_path \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_jobs_path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m     \u001b[43mobj_job_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_job_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_environment_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDATA_PRODUCT_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mENVIRONMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py:919\u001b[0m, in \u001b[0;36mJobMetaData.run_job_name\u001b[0;34m(cls, obj_env, spark, job_name, config, dbutils, data_product_id, environment, config_jobs_path)\u001b[0m\n\u001b[1;32m    915\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m    916\u001b[0m LoggerSingleton\u001b[38;5;241m.\u001b[39minstance(\n\u001b[1;32m    917\u001b[0m     NAMESPACE_NAME, SERVICE_NAME, data_product_id, environment\n\u001b[1;32m    918\u001b[0m )\u001b[38;5;241m.\u001b[39merror_with_exception(error_msg, exc_info)\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py:896\u001b[0m, in \u001b[0;36mJobMetaData.run_job_name\u001b[0;34m(cls, obj_env, spark, job_name, config, dbutils, data_product_id, environment, config_jobs_path)\u001b[0m\n\u001b[1;32m    893\u001b[0m     filter_value \u001b[38;5;241m=\u001b[39m j_a\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;66;03m# Call the run_job_action method with the extracted values\u001b[39;00m\n\u001b[0;32m--> 896\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_job_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjob_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished processing:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    908\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(result)\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py:1042\u001b[0m, in \u001b[0;36mJobMetaData.run_job_action\u001b[0;34m(cls, obj_env, spark, config, dbutils, action, export_schema, filter_column_name, filter_value)\u001b[0m\n\u001b[1;32m   1038\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m   1039\u001b[0m LoggerSingleton\u001b[38;5;241m.\u001b[39minstance(\n\u001b[1;32m   1040\u001b[0m     NAMESPACE_NAME, SERVICE_NAME, data_product_id, environment\n\u001b[1;32m   1041\u001b[0m )\u001b[38;5;241m.\u001b[39merror_with_exception(error_msg, exc_info)\n\u001b[0;32m-> 1042\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py:1002\u001b[0m, in \u001b[0;36mJobMetaData.run_job_action\u001b[0;34m(cls, obj_env, spark, config, dbutils, action, export_schema, filter_column_name, filter_value)\u001b[0m\n\u001b[1;32m    991\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ingress_processing(\n\u001b[1;32m    992\u001b[0m         obj_env,\n\u001b[1;32m    993\u001b[0m         config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    999\u001b[0m         environment,\n\u001b[1;32m   1000\u001b[0m     )\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_data_processing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1002\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_data_processing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_product_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_analytics_processing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1014\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrun_analytics_processing(\n\u001b[1;32m   1015\u001b[0m         obj_env,\n\u001b[1;32m   1016\u001b[0m         config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         environment,\n\u001b[1;32m   1024\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/job_metadata.py:534\u001b[0m, in \u001b[0;36mJobMetaData.run_data_processing\u001b[0;34m(obj_env_metadata, config, spark, dbutils, export_schema, filter_column_name, filter_value, data_product_id, environment)\u001b[0m\n\u001b[1;32m    532\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_datasets unfiltered count:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(msg)\n\u001b[0;32m--> 534\u001b[0m df_columns \u001b[38;5;241m=\u001b[39m \u001b[43mobj_env_metadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_column_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_product_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# Make sure apply table filters to columns dataframe\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    540\u001b[0m     filter_column_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filter_column_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filter_column_name\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m ):\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py:290\u001b[0m, in \u001b[0;36mEnvironmentMetaData.get_column_list\u001b[0;34m(cls, config, spark, dbutils, data_product_id, environment)\u001b[0m\n\u001b[1;32m    288\u001b[0m tenant_id \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maz_sub_tenant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    289\u001b[0m client_secret \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 290\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_product_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(file_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# default to empty DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_metadata_service/environment_metadata.py:381\u001b[0m, in \u001b[0;36mEnvironmentMetaData.get_file_size\u001b[0;34m(running_local, file_path, dbutils, data_product_id, environment, spark, client_id, client_secret, tenant_id)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the file size in bytes for the specified file path.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m    int: The size of the file in bytes.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    380\u001b[0m obj_env_file \u001b[38;5;241m=\u001b[39m cdc_environment_file\u001b[38;5;241m.\u001b[39mEnvironmentFile()\n\u001b[0;32m--> 381\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[43mobj_env_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_product_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_size\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py:729\u001b[0m, in \u001b[0;36mEnvironmentFile.get_file_size\u001b[0;34m(cls, running_local, path, dbutils, spark, data_product_id, environment, client_id, client_secret, tenant_id, account_name)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_file_size\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         file_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_exists\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrunning_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_product_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdbutils\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient_secret\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file_exists \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m             ddl_schema_3 \u001b[38;5;241m=\u001b[39m StructType(\n\u001b[1;32m    742\u001b[0m                 [\n\u001b[1;32m    743\u001b[0m                     StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 ]\n\u001b[1;32m    747\u001b[0m             )\n",
      "File \u001b[0;32m~/projects/cdh-ref/cdh_lava_core_lib/cdh_lava_core/cdc_tech_environment_service/environment_file.py:995\u001b[0m, in \u001b[0;36mEnvironmentFile.file_exists\u001b[0;34m(cls, running_local, path, data_product_id, environment, dbutils, client_id, client_secret, tenant_id)\u001b[0m\n\u001b[1;32m    993\u001b[0m path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/dbfs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dbutils \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 995\u001b[0m     \u001b[43mdbutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     b_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/dbutils.py:55\u001b[0m, in \u001b[0;36m_FsUtil.ls\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lists the contents of a directory \"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbfs\u001b[38;5;241m.\u001b[39mlist(\u001b[38;5;28mdir\u001b[39m):\n\u001b[1;32m     56\u001b[0m     name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     57\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FileInfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdbfs:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, name, f\u001b[38;5;241m.\u001b[39mfile_size, f\u001b[38;5;241m.\u001b[39mmodification_time))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/mixins/files.py:342\u001b[0m, in \u001b[0;36mDbfsExt.list\u001b[0;34m(self, path, recursive)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue:\n\u001b[1;32m    341\u001b[0m     path, queue \u001b[38;5;241m=\u001b[39m queue[\u001b[38;5;241m0\u001b[39m], queue[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 342\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m recursive \u001b[38;5;129;01mand\u001b[39;00m file_info\u001b[38;5;241m.\u001b[39mis_dir:\n\u001b[1;32m    344\u001b[0m             queue\u001b[38;5;241m.\u001b[39mappend(file_info\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/service/files.py:510\u001b[0m, in \u001b[0;36mDbfsAPI.list\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    508\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m, }\n\u001b[0;32m--> 510\u001b[0m json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/2.0/dbfs/list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m parsed \u001b[38;5;241m=\u001b[39m ListStatusResponse\u001b[38;5;241m.\u001b[39mfrom_dict(json)\u001b[38;5;241m.\u001b[39mfiles\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed \u001b[38;5;28;01mif\u001b[39;00m parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py:130\u001b[0m, in \u001b[0;36mApiClient.do\u001b[0;34m(self, method, path, query, headers, body, raw, files, data, response_headers)\u001b[0m\n\u001b[1;32m    126\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_agent_base\n\u001b[1;32m    127\u001b[0m retryable \u001b[38;5;241m=\u001b[39m retried(timeout\u001b[38;5;241m=\u001b[39mtimedelta(seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_timeout_seconds),\n\u001b[1;32m    128\u001b[0m                     is_retryable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_retryable,\n\u001b[1;32m    129\u001b[0m                     clock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg\u001b[38;5;241m.\u001b[39mclock)\n\u001b[0;32m--> 130\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mretryable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header \u001b[38;5;129;01min\u001b[39;00m response_headers \u001b[38;5;28;01mif\u001b[39;00m response_headers \u001b[38;5;28;01melse\u001b[39;00m []:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py:54\u001b[0m, in \u001b[0;36mretried.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         retry_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(err)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is allowed to retry\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retry_reason \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# raise if exception is not retryable\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     56\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrying: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (sleeping ~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m clock\u001b[38;5;241m.\u001b[39msleep(sleep \u001b[38;5;241m+\u001b[39m random())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/retries.py:33\u001b[0m, in \u001b[0;36mretried.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m clock\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m<\u001b[39m deadline:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     35\u001b[0m         last_err \u001b[38;5;241m=\u001b[39m err\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.10/envs/REFERENCE_DATA_DEV/lib/python3.10/site-packages/databricks/sdk/core.py:238\u001b[0m, in \u001b[0;36mApiClient._perform\u001b[0;34m(self, method, path, query, headers, body, raw, files, data)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok: \u001b[38;5;66;03m# internally calls response.raise_for_status()\u001b[39;00m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# TODO: experiment with traceback pruning for better readability\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;66;03m# See https://stackoverflow.com/a/58821552/277035\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         payload \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_nicer_error(response\u001b[38;5;241m=\u001b[39mresponse, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n",
      "\u001b[0;31mResourceDoesNotExist\u001b[0m: No file or directory exists on path abfss://cdh@davsynapseanalyticsdev.dfs.core.windows.net/raw/reference_data/config/bronze_sps_config_columns.csv."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "dbutils_exists = \"dbutils\" in locals() or \"dbutils\" in globals()\n",
    "if dbutils_exists is False:\n",
    "    # pylint: disable=invalid-name\n",
    "    dbutils = None\n",
    "\n",
    "running_local = dbutils is None\n",
    "\n",
    "if running_local is False:\n",
    "\n",
    "    # Get the current working directory\n",
    "    current_dir = os.getcwd()\n",
    "    print(\"Current Directory:\", current_dir)\n",
    "\n",
    "    # Go up two directories\n",
    "    parent_dir = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "    print(\"Parent Directory:\", parent_dir)\n",
    "\n",
    "    # Add the parent directory path to sys.path\n",
    "    if parent_dir not in sys.path:\n",
    "        sys.path.append(parent_dir)\n",
    "\n",
    "    core_dir = parent_dir + \"/cdh_lava_core_lib\"\n",
    "    print(core_dir)\n",
    "\n",
    "    # Add the parent directory path to sys.path\n",
    "    if core_dir not in sys.path:\n",
    "        sys.path.append(core_dir)\n",
    "\n",
    "    lib_dir = core_dir + \"/cdh_lava_core\"\n",
    "    print(lib_dir)\n",
    "\n",
    "    # Add the parent directory path to sys.path\n",
    "    if lib_dir not in sys.path:\n",
    "        sys.path.append(lib_dir)\n",
    "\n",
    "    # Now, list files in the parent directory\n",
    "    try:\n",
    "        files = os.listdir(parent_dir)\n",
    "        print(\"Files in Parent Directory:\", files)\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing {parent_dir}: {e}\")\n",
    "    current_file_dir = None  # or set a default path\n",
    "else:\n",
    "    # Fallback to using __file__ if not in Databricks\n",
    "    current_file_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # Resolve the path to its absolute form\n",
    "    peer_dir = os.path.join(current_file_dir, \"..\")\n",
    "    full_path = os.path.abspath(peer_dir)\n",
    "    # Print the full, resolved path\n",
    "    print(full_path)\n",
    "    # Add the peer directory to sys.path\n",
    "    sys.path.insert(0, full_path)\n",
    "\n",
    "import cdh_lava_core_lib.cdh_lava_core as cdh_lava_core\n",
    "\n",
    "# Define your default job name\n",
    "# \"process_data\"\n",
    "DEFAULT_JOB_NAME = \"process_data_where_source_abbreviation_name_is_phvs\"  # Replace with your actual default job name\n",
    "PACKAGE_NAME = \"global_reference\"\n",
    "ENVIRONMENT = \"DEV\"\n",
    "DATA_PRODUCT_ID = \"global_reference\"\n",
    "\n",
    "spark_exists = \"spark\" in locals() or \"spark\" in globals()\n",
    "if spark_exists is False:\n",
    "    # pylint: disable=invalid-name\n",
    "    spark = None\n",
    "\n",
    "print(f\"running_local: {running_local}\")\n",
    "initial_script_dir = (\n",
    "    os.path.dirname(os.path.abspath(__file__))\n",
    "    if \"__file__\" in globals()\n",
    "    else os.getcwd()\n",
    ")\n",
    "\n",
    "print(f\"initial_script_dir: {initial_script_dir}\")\n",
    "parent_dir = os.path.abspath(os.path.join(initial_script_dir, \"\"))\n",
    "\n",
    "print(f\"parent_dir: {parent_dir}\")\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from cdh_lava_core_lib import run_install_cdh_lava_core\n",
    "\n",
    "(\n",
    "    spark,\n",
    "    jobs_list,\n",
    "    job_names,\n",
    "    obj_environment_metadata,\n",
    "    obj_job_metadata,\n",
    "    config,\n",
    "    job_name,\n",
    ") = run_install_cdh_lava_core.setup_job(\n",
    "    running_local,\n",
    "    PACKAGE_NAME,\n",
    "    DEFAULT_JOB_NAME,\n",
    "    initial_script_dir,\n",
    "    dbutils,\n",
    "    spark,\n",
    "    ENVIRONMENT,\n",
    "    DATA_PRODUCT_ID,\n",
    ")\n",
    "\n",
    "if DEFAULT_JOB_NAME != \"Select job to run\":\n",
    "    config_jobs_path = config.get(\"config_jobs_path\")\n",
    "    obj_job_metadata.run_job_name(\n",
    "        obj_environment_metadata,\n",
    "        spark,\n",
    "        job_name,\n",
    "        config,\n",
    "        dbutils,\n",
    "        DATA_PRODUCT_ID,\n",
    "        ENVIRONMENT,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REFERENCE_DATA_DEV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
