{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANODI-Captum Demonstration\n",
    "\n",
    "In this short demo we will give a very basic explanation on how to use our library with the model interpretability tool [Captum](https://captum.ai/).\n",
    "\n",
    "We will use the MTAD-GAT-Model and the ECG-200-Datasets for our example, since all algorithms (using PyTorch and FastAI) are handeled analogously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the usual imports needed to use the algorithm as well as the IntegratedGradients from Captum. For this method we (can) only consider the model (see Captum_demo_feature_ablation for explanation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# change this to your systems settings\n",
    "current_dir = os.path.dirname(os.path.abspath(('/Users/timon/Documents/ANODI/anodi/anodi/tests/captum_demo.ipynb')))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.MTAD_GAT import MTAD_GAT\n",
    "\n",
    "from data.download import *\n",
    "from data.DatasetSpecification import DATASETS\n",
    "from metrics.cmetrics import *\n",
    "from captum.attr import IntegratedGradients\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the MTAD-GAT algorithm and obtain the prepared PyTorch model from the FastAI-Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/Documents/ANODI/anodi/anodi/data/download.py:78: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pandas.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss  time    \n",
      "Epoch 1/1 : |████████████████████--------------------| 50.00% [1/2 00:00<00:00]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/Documents/ANODI/anodi/anodi/data/preprocessing.py:13: FutureWarning: DataFrame.interpolate with method=bfill is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.interpolate(method=\"bfill\", axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2.941625    None        00:00                                                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timon/miniforge3/envs/anodi/lib/python3.10/site-packages/fastprogress/fastprogress.py:73: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "train = DATASETS[\"ECG200_TRAIN\"]\n",
    "test = DATASETS[\"ECG200_TEST\"]\n",
    "\n",
    "alg = MTAD_GAT(dataset_specification=train, \n",
    "               batch_size=28, \n",
    "               window_length=4,\n",
    "               learning_rate=1e-3,\n",
    "               L=1,\n",
    "               verbose=True,\n",
    "               dynamic_pot=True,\n",
    "               level=0.6)\n",
    "alg.fit(epoch_num=1)\n",
    "\n",
    "model = alg.learner.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model return a quadruple at predict, we only need the test_pred_df as prediciton.\n",
    "Next, we pass the (modified) model to the IntegratedGradients and prepare test inputs and the baseline inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_f(in_vec):\n",
    "    res = model.forward(in_vec)\n",
    "    return res[2][0]\n",
    "\n",
    "\n",
    "ig = IntegratedGradients(modified_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use the integrated Gradients method to obtain information on which features had which impact on the outputs of the model. Note that the output of the model is a reconstruction of the inputs since we are dealing with an unsupervised learning algorithm.\n",
    "\n",
    "For demonstration purposes, we use random and zero inputs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = torch.rand(28,4,96)\n",
    "baseline = torch.zeros(28,4,96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Integrated Gradients to get attributions and delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG Attributions: tensor([[[-3.9913e-08, -8.8001e-07, -5.8852e-07,  ...,  6.9981e-07,\n",
      "           1.4898e-06,  5.5813e-07],\n",
      "         [-7.3169e-07, -1.7112e-07,  9.5067e-07,  ..., -3.3682e-07,\n",
      "          -7.3534e-09, -8.1155e-08],\n",
      "         [ 2.6222e-07, -3.2600e-07, -1.1314e-06,  ..., -3.4570e-07,\n",
      "          -8.9932e-08, -8.0977e-08],\n",
      "         [ 4.5227e-07, -1.0824e-07, -8.7441e-08,  ..., -1.2056e-06,\n",
      "          -8.6982e-07, -1.4850e-07]],\n",
      "\n",
      "        [[-2.1055e-07, -1.7675e-07,  1.5221e-07,  ...,  1.0617e-06,\n",
      "           1.8596e-07,  9.3661e-08],\n",
      "         [ 2.4079e-07, -2.1432e-07,  4.3604e-07,  ..., -3.4992e-07,\n",
      "           6.3780e-07,  4.1985e-07],\n",
      "         [-2.4201e-07, -8.7014e-07, -3.7085e-07,  ...,  3.6410e-07,\n",
      "          -7.3937e-07, -1.1535e-07],\n",
      "         [ 1.0717e-06, -3.8623e-07,  1.1559e-07,  ..., -2.2903e-07,\n",
      "          -1.6260e-06, -1.8149e-07]],\n",
      "\n",
      "        [[ 8.6348e-08, -2.1598e-07,  7.7145e-09,  ...,  5.0976e-08,\n",
      "           3.6291e-08, -7.4281e-08],\n",
      "         [-2.0409e-07, -6.9764e-07,  1.1176e-06,  ...,  1.3467e-08,\n",
      "           2.8863e-07,  1.1231e-07],\n",
      "         [ 6.8086e-07, -1.0834e-06, -6.8710e-07,  ...,  1.1504e-08,\n",
      "          -3.5324e-08, -1.1730e-06],\n",
      "         [-2.0157e-07, -2.4805e-07,  5.6299e-08,  ..., -3.7298e-07,\n",
      "          -5.5693e-07, -4.0131e-07]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.8992e-07, -4.2293e-07, -3.4054e-07,  ...,  2.6292e-07,\n",
      "           1.6286e-07, -4.7329e-08],\n",
      "         [-1.1357e-07, -5.7417e-08,  3.6526e-08,  ..., -6.5243e-08,\n",
      "           3.6782e-08, -5.6225e-09],\n",
      "         [ 4.2531e-07, -9.1563e-07, -4.3211e-07,  ...,  2.0422e-10,\n",
      "          -2.9236e-07, -9.0501e-07],\n",
      "         [ 2.8983e-08, -5.2038e-07, -1.8148e-07,  ..., -2.7276e-07,\n",
      "          -1.3862e-07, -1.1052e-07]],\n",
      "\n",
      "        [[-4.6267e-07, -4.1859e-07, -3.8656e-07,  ...,  8.3419e-07,\n",
      "           1.6490e-06,  1.1205e-07],\n",
      "         [-1.0482e-07, -5.9413e-07,  7.5531e-08,  ..., -5.7771e-07,\n",
      "          -3.3276e-08, -1.0066e-07],\n",
      "         [ 5.1339e-09, -1.8650e-06, -7.8143e-07,  ..., -5.6686e-08,\n",
      "          -4.8537e-07, -1.7113e-07],\n",
      "         [-9.7727e-08, -7.2208e-07,  2.6985e-07,  ..., -3.7753e-07,\n",
      "          -3.1542e-07, -1.1646e-06]],\n",
      "\n",
      "        [[ 7.1708e-07, -2.7556e-07, -6.5068e-08,  ..., -2.5318e-07,\n",
      "           5.1917e-07,  4.2558e-07],\n",
      "         [ 1.9951e-07, -1.3910e-07,  2.6289e-07,  ..., -3.3279e-07,\n",
      "           5.4992e-07,  4.7359e-07],\n",
      "         [-4.0965e-07, -3.4339e-07, -1.2404e-06,  ..., -2.5726e-10,\n",
      "          -9.4561e-07, -2.7933e-07],\n",
      "         [ 2.3490e-08, -5.6367e-07,  1.9510e-07,  ..., -2.5414e-07,\n",
      "          -4.6693e-07, -1.5544e-07]]], dtype=torch.float64)\n",
      "Convergence Delta: tensor([-0.3334, -0.3402, -0.3320, -0.3265, -0.3389, -0.2985, -0.3281, -0.3116,\n",
      "        -0.3084, -0.3340, -0.3113, -0.3289, -0.3024, -0.3152, -0.3456, -0.3412,\n",
      "        -0.3346, -0.3377, -0.3468, -0.3130, -0.3411, -0.3528, -0.3236, -0.3251,\n",
      "        -0.3200, -0.3226, -0.3246, -0.3341], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "attributions, delta = ig.attribute(input, baseline, return_convergence_delta=True)\n",
    "print('IG Attributions:', attributions)\n",
    "print('Convergence Delta:', delta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anodi_re",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
