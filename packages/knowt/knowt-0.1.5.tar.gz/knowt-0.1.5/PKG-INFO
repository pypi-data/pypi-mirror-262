Metadata-Version: 2.1
Name: knowt
Version: 0.1.5
Summary: Private, personalized searchable knowledge base, from your own notes.
Author-email: Hobson Lane <git@totalgood.com>, Ethan Cavill <ethancavill@gmail.com>
License: GPLv3+
Keywords: NLP,LLM,vector-search,ANN,numpy,search,semantic search,RAG,personal assistant,command line
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: ipython
Requires-Dist: joblib<1.4,>=1.3.2
Requires-Dist: jsonlines
Requires-Dist: jupyter
Requires-Dist: jupyter-console
Requires-Dist: numpy<1.27,>=1.26.2
Requires-Dist: pandas<2.3,>=2.2.0
Requires-Dist: pytest-coverage
Requires-Dist: scikit-learn<1.4,>=1.3.2
Requires-Dist: spacy<3.8,>=3.7.2
Provides-Extra: llm
Requires-Dist: python-dotenv; extra == "llm"
Requires-Dist: openai; extra == "llm"
Provides-Extra: test
Requires-Dist: pytest-coverage; extra == "test"
Requires-Dist: black; extra == "test"
Requires-Dist: twine; extra == "test"
Requires-Dist: pip; extra == "test"
Requires-Dist: build; extra == "test"
Requires-Dist: wheel; extra == "test"
Provides-Extra: ann
Requires-Dist: py-lsh; extra == "ann"
Provides-Extra: vaex
Requires-Dist: vaex<4.18,>=4.17.0; extra == "vaex"
Provides-Extra: dask
Requires-Dist: dask; extra == "dask"
Provides-Extra: transformers
Requires-Dist: sentence-transformers<2.3,>=2.2.2; extra == "transformers"
Provides-Extra: all
Requires-Dist: test; extra == "all"
Requires-Dist: ann; extra == "all"
Requires-Dist: llm; extra == "all"
Requires-Dist: spacy; extra == "all"
Requires-Dist: vaex; extra == "all"
Requires-Dist: dask; extra == "all"
Requires-Dist: transformers; extra == "all"

# Knowt
Knowt turns notes into knowledge.
You can search your notes for the name of that person you saw at the cafe last week or even have a conversation with your past self about anything at all.
It won't write your term paper for you, or draw you dreamy pictures, but it will help you remember the important things, the things that your favorite humans wrote down.

## Getting started
My favorite humans these days are on open source communities like Hacker Public Radio.
So `knowt` comes with all the show notes from every on of the 4,000+ HPR episodes recorded in its 15+ years of cointinuous broadcasting.
What questions do you have for the 100s of agalmic contributors to HPR?

```bash
$ pip install knowt
$ knowt what is Haycyon?
```


## Installation

#### Python virtual environment

To set up the project environment, follow these steps:

1. Clone the project repository or download the project files to your local machine.
2. Navigate to the project directory.
3. Create a Python virtual environment in the project directory:

```bash
pip install virtualenv
python -m virtualenv .venv
```

4. Activate the virtual environment (mac/linux):

```bash
source .venv/bin/activate
```

#### Install dependencies

Not that you have a virtual environment, you're ready to install some Python packages and download language models (spaCy and BERT).

1. Install the required packages using the `requirements.txt` file:

```bash
pip install -e .
```

2. Download the small BERT embedding model (you can use whichever open source model you like):

```bash
python -c 'from sentence_transformers import SentenceTransformer; sbert = SentenceTransformer("paraphrase-MiniLM-L6-v2")'
```

#### Quick start

You can search an example corpus of nutrition and health documents by running the `search_engine.py` script.

#### Search your personal docs

1. Replace the text files in `data/corpus` with your own.
2. Start the command-line search engine with:

```bash
python search_engine.py --refresh
```

The `--refresh` flag ensures that a fresh index is created based on your documents.
Otherwise it may ignore the `data/corpus` directory and reuse an existing index and corpus in the `data/cache` directory.

The `search_engine.py` script will first segement the text files into sentences.
Then it will create a "reverse index" by counting up words and character patterns in your documents.
It will also creat semantic embeddings to allow you to as questions about vague concepts without even knowing any the words you used in your documents.

## Contributing

Submit an Issue (bug or feature suggestion) or a Merge Request and someone will  respond within the week.
